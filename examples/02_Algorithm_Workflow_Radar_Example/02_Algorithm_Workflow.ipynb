{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\"; span style=\"color:#336699\"><b><h2> Algorithm Workflow </h2></b></div>\n",
    "<hr style=\"border:2px solid #0077b9;\">\n",
    "<br/>\n",
    "<div style=\"text-align: center;font-size: 90%;\">\n",
    "    Helvécio B. Leal Neto, <sup><a href=\"https://orcid.org/0000-0002-7526-2094\"><i class=\"fab fa-lg fa-orcid\" style=\"color: #a6ce39\"></i></a></sup>\n",
    "    Alan J. P. Calheiros<sup><a href=\"https://orcid.org/0000-0002-7526-2094\"><i class=\"fab fa-lg fa-orcid\" style=\"color: #a6ce39\"></i></a></sup>\n",
    "   :<br/><br/>\n",
    " :  National Institute for Space Research (INPE)\n",
    "    <br/>\n",
    "    Avenida dos Astronautas, 1758, Jardim da Granja, São José dos Campos, SP 12227-010, Brazil\n",
    "    <br/><br/>\n",
    "    Contact: <a href=\"mailto:helvecio.neto@inpe.br\">helvecio.neto@inpe.br</a>, <a href=\"mailto:alan.calheiros@inpe.br\">alan.calheiros@inpe.br</a>\n",
    "    <br/><br/>\n",
    "    Last Update: Nov 1, 2024\n",
    "</div>\n",
    "<br/>\n",
    "<div style=\"text-align: justify;  margin-left: 25%; margin-right: 25%;\">\n",
    "<b>Abstract.</b> This Jupyter notebook demonstrates the complete processing flow of the tracking process of pyForTraCC algorithm. There you can check the example of tracking using radar data.\n",
    "</div>    \n",
    "<br/>\n",
    "<div style=\"text-align: justify;  margin-left: 15%; margin-right: 15%;font-size: 75%; border-style: solid; border-color: #0077b9; border-width: 1px; padding: 5px;\">\n",
    "    <b>This Jupyter Notebook was based on the <a href=\"https://github.com/fortracc-project/pyfortracc\">\"pyfortracc\"</a> example from the pyFortracc:</b>\n",
    "    <div style=\"margin-left: 10px; margin-right: 10px; margin-top:10px\">\n",
    "      <p> Leal Neto, H.B.; Calheiros, A.J.P.;  pyForTraCC Algorithm. São José dos Campos, INPE, 2024. <a href=\"https://github.com/fortracc-project/pyfortracc\" target=\"_blank\"> Online </a>. </p>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schedule\n",
    "\n",
    " [1. Installation](#install)<br>\n",
    " [2. Radar Input Data](#data)<br>\n",
    " [3. Read Function](#read)<br>\n",
    " [4. Tracking Parameters](#parameters)<br>\n",
    " [5. Algorithm Workflow](#parameters)<br>\n",
    " [- Features Extraction](#features)<br>\n",
    " [- Spatial Operations](#spatial)<br>\n",
    " [- Cluster Link](#link)<br>\n",
    " [6. Explore Output](#output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='install'></a>\n",
    "#### 1. Installation\n",
    "\n",
    "Installing the pyFortraCC package can be done using the pip install command. \n",
    "\n",
    "All dependencies will be installed in the current Python environment and the code will be ready to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install directly from github\n",
    "!pip3 install --upgrade git+https://github.com/fortracc/pyfortracc.git@main#egg=pyfortracc &> /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='data'></a>\n",
    "#### 1. Radar Input Data\n",
    "\n",
    "The data in this example corresponds to a small sample of scans from the S-Band Radar located in the city of Manaus-AM Brazil.<br>\n",
    " Data processed and published by Schumacher, Courtney and Funk, Aaron (2018) were separated, <br>\n",
    " and are available in full on the ARM platform https://www.arm.gov/research/campaigns/amf2014goamazon.<br>\n",
    " This data is part of the GoAmazon2014/5 project and is named \"Three-dimensional Gridded S-band Reflectivity and Radial Velocity<br>\n",
    " from the SIPAM Manaus S-band Radar dataset\".<br>\n",
    "https://doi.org/10.5439/1459573\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the exemple input files\n",
    "!pip3 install --upgrade --no-cache-dir gdown &> /dev/null\n",
    "!gdown 'https://drive.google.com/uc?id=1UVVsLCNnsmk7_wOzVrv4H7WHW0sz8spg'\n",
    "!unzip -qq -o input.zip\n",
    "!rm -rf input.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='read'></a>\n",
    "#### 3. Read Function\n",
    "\n",
    "The downloaded data is compressed with the .gz extension, however, it is of the netCDF4 type. The variable that represents reflectivity is DBZc. This data also has multiple elevations, and we arbitrarily chose elevation 5, which corresponds to the volumetric scan level at 2.5 km height. We extract the data and apply a NaN value to the data mask -9999."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Read function\n",
    "import gzip\n",
    "import netCDF4\n",
    "import numpy as np\n",
    "\n",
    "def read_function(path):\n",
    "    variable = \"DBZc\"\n",
    "    z_level = 5 # Elevation level 2.5 km\n",
    "    with gzip.open(path) as gz:\n",
    "        with netCDF4.Dataset(\"dummy\", mode=\"r\", memory=gz.read()) as nc:\n",
    "            data = nc.variables[variable][:].data[0,z_level, :, :][::-1, :]\n",
    "            data[data == -9999] = np.nan\n",
    "    gz.close()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualize the data, we use an function from pyFortraCC that reads the data and create an animation of the radar scan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyfortracc import plot_animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the data using the plot_animation function\n",
    "plot_animation(path_files='input/*.gz', # Path to the files\n",
    "                          read_function=read_function, # Read function\n",
    "                          num_frames=10, min_val=0, max_val=60, # Number of frames and maximum value\n",
    "                          cbar_title='dBZ') # Colorbar title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='parameters'></a>\n",
    "#### 4. Tracking Parameters\n",
    "\n",
    "For this example, we will track reflectivity clusters at multiple thresholds and sizes <br>Arbitrarily selecting thresholds of 20, 30 and 35 dBZ with clusters of 5,4 and 3 pixels <br>of minimum size. The segmentation operator will be >=, that is, the clusters will be <br>segmented in order of greatest equal for each threshold and the delta of the observations <br>is 12 minutes.<br>\n",
    "To improve the precision of the tracking, we will use the DBSCAN algorithm with a elpsilon with 3 pixels,<br>\n",
    "this method considers the spatial distance pixels around the cluster and includes them in the same cluster.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Name list dictionary of mandatory parameters\n",
    "name_list = {}\n",
    "name_list['input_path'] = 'input/' # path to the input data\n",
    "name_list['output_path'] = 'output/' # path to the output data\n",
    "name_list['timestamp_pattern'] = 'sbmn_cappi_%Y%m%d_%H%M.nc.gz' # timestamp file pattern\n",
    "name_list['thresholds'] = [20,30,35] # in dbz\n",
    "name_list['min_cluster_size'] = [3,3,3] # in number of points per cluster\n",
    "name_list['operator'] = '>=' # '>= - <=' or '=='\n",
    "name_list['delta_time'] = 12 # in minutes\n",
    "name_list['min_overlap'] = 20 # Minimum overlap between clusters in percentage\n",
    "\n",
    "# Optional parameters, if not set, the algorithm will not use geospatial information\n",
    "name_list['lon_min'] = -62.1475 # Min longitude of data in degrees\n",
    "name_list['lon_max'] = -57.8461 # Max longitude of data in degrees\n",
    "name_list['lat_min'] = -5.3048 # Min latitude of data in degrees\n",
    "name_list['lat_max'] = -0.9912 # Max latitude of data in degrees\n",
    "\n",
    "name_list['cluster_method'] = 'dbscan' # DBSCAN Clustering method\n",
    "name_list['eps'] = 3 # in pixels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='workflow'></a>\n",
    "#### 5. Algorithm Workflow\n",
    "\n",
    "In this example we will use the modules separately, that is, each internal module of the pyForTraCC algorithm will be called individually.<br>\n",
    "The track workflow is divided into four modules:\n",
    "<ol>\n",
    "  <li><b>Feature detection</b>: Focuses on identifying distinct characteristics for precise tracking.\n",
    "  </li>\n",
    "  <li><b>Spatial Operations</b>: Involves spatial operations (intersection, union, difference, etc) between the features of consecutive time steps (t and t-1).\n",
    "  <li><b>Trajectory Linking</b>: Passing one by one the time steps, the algorithm link the features of consecutive time steps based on the association created in the previous step. The algorithm create a trajectory for each feature.\n",
    "  <li><b>Concatenate</b>:\n",
    "  </li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - Features Extraction\n",
    "Image processing strategies were combined with clustering and rasterization algorithms to achieve the results obtained by the extract_features function. The following sequence is present in the implementation of the algorithm:\n",
    "\n",
    "1. Read the file using the read_funcion.\n",
    "2. Image segmentation according to each threshold.\n",
    "3. Labeling of clusters. Two clustering options are implemented (DBSCAN and ndimage). \n",
    "5. Vectorization of the clusters using rasterio.features.shapes to acquire the boundary polygon and the centroid of the clusters.\n",
    "\n",
    "<span> <img src=\"./img/features.png\" style=\"height:320px;\" align=\"left\"></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyfortracc import features_extraction\n",
    "\n",
    "# Note: If you are running this notebook using MacOS, you may need to set parallel=False.\n",
    "features_extraction(name_list, read_function, parallel=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of submodules of pyForTraCC, the algorithm returns a dataframe into a parquet file. \n",
    "The dataframe for features extraction contains the following columns:\n",
    "\n",
    "- timestamp: The timestamp of the radar scan, based on name_list['timestamp_pattern'].\n",
    "- cluster_id: The cluster identification by clusterization algorithm.\n",
    "- threshold_level: The threshold level of the cluster.\n",
    "- threshold: The threshold value of the cluster.\n",
    "- size: The size of the cluster (in pixels).\n",
    "- min max mean std: The minimum, maximum, mean and standard deviation of values of the cluster.\n",
    "- array_values: The values of the cluster.\n",
    "- array_x array_y: The x and y coordinates of the cluster.\n",
    "- geometry: The boundary polygon of the cluster.\n",
    "- file: The file name of the radar scan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "features = sorted(glob.glob(name_list['output_path'] + '/track/processing/features/*.parquet'))\n",
    "features = pd.concat(pd.read_parquet(f) for f in features)\n",
    "display(features.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - Spatial operations \n",
    "\n",
    "Spatial operations are fundamental in Geographic Information Systems (GIS) and spatial databases. And the Geopandas implementation simplifies the process by combining GeoDataframes stored in .parquet files by features extraction module. Based on their spatial relationships between clusters of current and previous times, we use the Spatial Join to create associations between boundary clusters of consecutive times. The algoritmo use this method performs to various types of spatial joins such as overlays, within, contains.\n",
    "\n",
    "To demonstrate the basic functioning of the spatial operations mode, we will use as a base two consecutive times listed here as the variables cur_frame and prev_frame, which store information about the characteristics of the systems for each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.wkt import loads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the features parquet files\n",
    "cur_frame = pd.read_parquet('./output/track/processing/features/20140816_1012.parquet')\n",
    "prev_frame = pd.read_parquet('./output/track/processing/features/20140816_1000.parquet')\n",
    "cur_frame['geometry'] = cur_frame['geometry'].apply(loads)\n",
    "prev_frame['geometry'] = prev_frame['geometry'].apply(loads)\n",
    "# Convert to geo dataframes where column is geometry\n",
    "cur_frame = gpd.GeoDataFrame(cur_frame)\n",
    "prev_frame = gpd.GeoDataFrame(prev_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In figure below, we can see the spatial operations between the clusters of two consecutive times. The Red polygons represent the clusters of the current time and the blue polygons represent the clusters of the previous time. And its possible to see these clusters have a spatial relationship between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the features and see have a visual overlap between the geometries\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "cur_frame.boundary.plot(ax=ax, color='red', alpha=0.5, label='Current Frame')\n",
    "prev_frame.boundary.plot(ax=ax, color='blue', alpha=0.5, label='Previous Frame')\n",
    "plt.legend( loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To demonstrate one of the operations performed in the algorithm, below is the GeoPandas sjoin function that checks the overlaps between the two GeoDataframes. \n",
    "Note that the return of the function will be another GeoDataframe, however only the index and index_right columns are of interest to us, \n",
    "as in these columns we have the information we need to make the associations between the geometries of the consecutive time clusters.\n",
    "In addition to the overlap operation, there are several others that can be seen at:\n",
    "https://shapely.readthedocs.io/en/latest/manual.html#binary-predicates\n",
    "\n",
    "The result of overlaps is stored into a dataframe containing the indexes of the clusters of the current and previous times that have a spatial relationship between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the spatial join between the previous and current frame\n",
    "overlaps = gpd.sjoin(cur_frame, prev_frame, how='inner',predicate='overlaps')[['index_right']].reset_index()\n",
    "# Ex: index column represents the index of the current frame and index_right represents the index of the previous frame\n",
    "overlaps.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, the spatial operations module also has additional vector extraction methods. These methods are covered in the work https://doi.org/10.3390/rs14215408\n",
    "\n",
    "To activate the methods just add the flags to the name_list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add correction methods\n",
    "name_list['spl_correction'] = True # Perform the correction at Splitting events\n",
    "name_list['mrg_correction'] = True # Perform the correction at Merging events\n",
    "name_list['inc_correction'] = True # Perform the correction using Inner Core vectors\n",
    "name_list['opt_correction'] = True # Perform the correction using the Optical Flow method (New Method)\n",
    "name_list['elp_correction'] = True # Perform the correction using the Ellipse method (New Method)\n",
    "name_list['validation'] = True # It is used to perform the validation of the correction methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run the spatial operations module, we need to call the function spatial_operations and pass the name_list as a parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyfortracc import spatial_operations\n",
    "\n",
    "# (Note: If you are running this notebook using MacOS, you may need to set parallel=False)\n",
    "spatial_operations(name_list, read_function, parallel=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataframe for spatial operations contains the following columns:\n",
    "\n",
    "- status: The status of the spatial operation, possible values are: NEW, CON, MRG, SPL, SPL/MRG\n",
    "- threshold_level: The threshold level of the cluster.\n",
    "- inside_clusters: Number of clusters inside the current threshold level cluster.\n",
    "- past_idx: The index of the cluster in the previous time.\n",
    "- inside_idx: The index of the cluster inside the current cluster.\n",
    "- merge_idx: The index of the cluster merged at previous time by the current cluster.\n",
    "- split_pr_idx: The index of the cluster split at previous time by the current cluster.\n",
    "- split_cr_idx: The index of the cluster split at current time by the previous cluster.\n",
    "- overlap: The overlap area between the clusters.\n",
    "- within: If is a within cluster. (True or False)\n",
    "- contains: If is a contains cluster. (True or False)\n",
    "- board: If is a cluster at the board. (True or False)\n",
    "- board_idx: The index of the cluster at the other side of the board.\n",
    "- u_: The u component of the cluster (in pixels or degrees, depending if run using geographic coordinates).\n",
    "- v_: The v component of the cluster (in pixels or degrees, depending if run using geographic coordinates).\n",
    "- trajectory: The trajectory of the cluster (LineString).\n",
    "- vector_field: The vector field of the cluster (MultiLineString).\n",
    "- expansion: The expansion rate between the clusters of consecutive times.\n",
    "- u_spl: The u component of the cluster by Split Correction.\n",
    "- v_spl: The v component of the cluster by Split Correction.\n",
    "- u_mrg: The u component of the cluster by Merge Correction.\n",
    "- v_mrg The v component of the cluster by Merge Correction.\n",
    "- u_inc: The u component of the cluster by Inner Cores Correction.\n",
    "- v_inc: The v component of the cluster by Inner Cores Correction.\n",
    "- u_opt: The u component of the cluster by Optical Flow Correction.\n",
    "- v_opt: The v component of the cluster by Optical Flow Correction.\n",
    "- u_elp: The u component of the cluster by Elliptical Correction.\n",
    "- v_elp: The v component of the cluster by Elliptical Correction.\n",
    "- u_noc: The u component of the cluster by No Correction.\n",
    "- v_noc: The v component of the cluster by No Correction.\n",
    "- far: The False Alarm Rate of method, if the validation is True into a name_list.\n",
    "- method: The best method of correction, if the validation is True into a name_list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the spatial parquet files\n",
    "spatial = sorted(glob.glob(name_list['output_path'] + '/track/processing/spatial/*.parquet'))\n",
    "spatial_df = pd.concat(pd.read_parquet(f) for f in spatial)\n",
    "display(spatial_df.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cluster Link\n",
    "\n",
    "The cluster connection module makes the association between consecutive time tables by associating the cluster indices that were identified by the spatial operations module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyfortracc import cluster_linking\n",
    "\n",
    "# This module only works in serial mode\n",
    "cluster_linking(name_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bellow we show how cluster link works. Set two spatial parquets from consecutive timestamps. And show the association between them based on indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read current and previous frames parquet files\n",
    "cur_frame = pd.read_parquet('output/track/processing/spatial/20140816_1212.parquet')\n",
    "prv_frame = pd.read_parquet('output/track/processing/spatial/20140816_1200.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The association is made by the indexes of the clusters of the current and previous times that have a spatial relationship between them. The algorithm uses the indexes of the clusters that have a spatial relationship between them to create a trajectory for each cluster.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The association uses the column 'past_idx' to link the previous frame with the current frame\n",
    "cur_frame[['past_idx']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The association is performed by linking the 'past_idx' column with the index of the previous frame\n",
    "prv_frame.loc[cur_frame['past_idx'].dropna().astype(int).values].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the link is made, the algorithm creates Unique IDs (uid) for the same cluster in different times. The uid is a unique identifier for each cluster that is maintained throughout the tracking process. For clusters of threshold level 0, the uid is a integer number, for inner clusters, the uid is called iuid, and have a integer part of the uid and a decimal part that represents the inner cluster. The uid and iuid is a unique identifier for each cluster that is maintained throughout the tracking process. Additionally, the algorithm creates a trajectory for each cluster and a lifetime of the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the linking results\n",
    "linked = sorted(glob.glob(name_list['output_path'] + '/track/processing/linked/*.parquet'))\n",
    "linking_df = pd.concat(pd.read_parquet(f) for f in linked)\n",
    "linking_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenate \n",
    "\n",
    "To simplify the process of running the algorithm, we have created a function that concatenates the results of the previous modules. The function receives the name_list as a parameter and creates a single parquet file for each timestamp of track process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyfortracc import concat\n",
    "\n",
    "# Concatenate the features, spatial and linking dataframes into a single dataframe\n",
    "concat(name_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of concatenate is a entity called tracking table. The tracking table is the generalized output  located in the output directory of name_list['output'] ('output_path/trackingtable'). The information obtained in the tracking process is stored in a tabular format, and is organized according to the tracking time. Listed below are the names of the columns (output variables) and what they represent.\n",
    "\n",
    "- Each row of tracking table is related to a cluster at its corresponding threshold level. \n",
    "- The information spans from unique identifiers and descriptive statistics to geometric properties and temporal features. \n",
    "- The Tracking table structure provides a comprehensive view of grouped entities, facilitating analysis and understanding of patterns across different threshold levels.\n",
    "\n",
    "Tracking table columns:\n",
    "\n",
    "*   **timestamp** (datetime64[us]): Temporal information of cluster.\n",
    "*   **uid** (float64): Unique idetifier of cluster.\n",
    "*   **iuid** (float64): Internal Unique idetifier of cluster.\n",
    "*   **threshold_level** (int64): Level of threshold.\n",
    "*   **threshold** (float64): Specific threshold.\n",
    "*   **status** (object): Entity status (NEW, CONTINUOUS, SPLIT, MERGE, SPLIT/MERGE)\n",
    "*   **u_, v_** (float64): Vector components.\n",
    "*   **inside_clusters** (object): Number of inside clusters.\n",
    "*   **size** (int64): Cluster size in pixels.\n",
    "*   **min, mean, max, std** (float64): Descriptive statistics.\n",
    "*   **delta_time** (timedelta64[us]): Temporal variation.\n",
    "*   **file** (object): Associated file name.\n",
    "*   **array_y, array_x** (object): Cluster array coordinates.\n",
    "*   **vector_field** (object): Associated vector field.\n",
    "*   **trajectory** (object): Cluster's trajectory.\n",
    "*   **geometry** (object):  Boundary geometric representation of the cluster.\n",
    "*   **lifetime** (int64): Cluster lifespan in minutes.\n",
    "*   **duration** (int64): Cluster duration in minutes.\n",
    "*   **genesis** (int64): Cluster genesis, with genesis: 1, active: 0, and death: -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The tracking table is saved in the output path\n",
    "tracking_files = sorted(glob.glob(name_list['output_path'] + '/track/trackingtable/*.parquet'))\n",
    "tracking_table = pd.concat(pd.read_parquet(f) for f in tracking_files)\n",
    "display(tracking_table.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resumed track Function\n",
    "\n",
    "All the process showed above is resumed in the track function. The track function is the main function of the pyForTraCC algorithm. It receives the name_list as a parameter and runs the entire tracking process. The track function is responsible for calling the internal modules of the algorithm in the correct order, and for creating the tracking table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyfortracc as pf\n",
    "\n",
    "# Track function\n",
    "pf.track(name_list, read_function, parallel=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore the results in tracking table\n",
    "\n",
    "To explore the results of the tracking process, we can use the tracking table. For this example, we will find the with a max lifetime and explore the results showing the track process using animation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get two maxlifetime clusters from the track_table\n",
    "maxlifetime = 2\n",
    "max_lifetimes = tracking_table.groupby('uid').size().nlargest(maxlifetime).index.values\n",
    "max_clusters = tracking_table[tracking_table['uid'].isin(max_lifetimes)]\n",
    "print('The clusters with the highest lifetime are the uids: {}'.format(max_lifetimes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the maxlifetime system in the tracking table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the tracking data for periods of time. Note: If the min and max value is a larger time interval, \n",
    "# the plot will be slower\n",
    "plot_animation(read_function=read_function, # Read function\n",
    "                          name_list=name_list, # Name list dictionary\n",
    "                          uid_list=max_lifetimes.tolist(), # List of uids\n",
    "                          start_timestamp = max_clusters['timestamp'].min().strftime('%Y-%m-%d %H:%M:%S'), \n",
    "                          end_timestamp= max_clusters['timestamp'].max().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "                          cbar_title='dBZ', # Colorbar title\n",
    "                          threshold_list=[20], # Threshold list\n",
    "                          trajectory=True, # Plot the trajectory\n",
    "                          max_val=60, # Maximum value for the colorbar\n",
    "                          min_val=20, # Minimum value for the colorbar\n",
    "                          info_cols=['uid','method','far'],\n",
    "                          background='google', # Background type\n",
    "                          )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyfortracc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
